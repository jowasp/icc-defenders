{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plac\n",
    "import random\n",
    "import pandas as pd\n",
    "import textacy.extract\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lives_in_relations(doc):\n",
    "    # merge entities and noun chunks into one token\n",
    "    spans = list(doc.ents) + list(doc.noun_chunks)\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "\n",
    "    relations = []\n",
    "    for location in filter(lambda w: w.ent_type_ == 'LOC', doc):\n",
    "        if location.dep_ in ('attr', 'dobj'):\n",
    "            subject = [w for w in location.head.lefts if w.dep_ == 'nsubj']\n",
    "            if subject:\n",
    "                subject = subject[0]\n",
    "                relations.append((subject, location))\n",
    "        elif location.dep_ == 'pobj' and location.head.dep_ == 'prep':\n",
    "            relations.append((location.head.head, location))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "Entities [('Goma', 'LOC')]\n",
      "Entities [('Marcus BRODY.', 'PERSON')]\n",
      "Entities [('Chief', 'RANK')]\n",
      "Entities [('Goma', 'LOC')]\n",
      "Entities [('Chief', 'RANK')]\n",
      "Entities [('Goma', 'LOC')]\n",
      "Entities [('2002', 'DATE')]\n",
      "LABEL:  Marcus BRODY. || NODE TYPE: PERSON\n",
      "LABEL:  2002 || NODE TYPE: DATE\n",
      "LABEL:  Goma || NODE TYPE: LOC\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:  Rebels || NODE TYPE: PRODUCT\n",
      "LABEL:  Goma || NODE TYPE: LOC\n",
      "LABEL:  Government || NODE TYPE: LOC\n",
      "LABEL:  Congo || NODE TYPE: GPE\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:  Chief || NODE TYPE: RANK\n",
      "LABEL:  Rebels || NODE TYPE: FAC\n",
      "LABEL:    || NODE TYPE: ORG\n",
      "LABEL:  Goma || NODE TYPE: LOC\n",
      "LABEL:  Government || NODE TYPE: LOC\n",
      "LABEL:  Congo || NODE TYPE: GPE\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:  Chief || NODE TYPE: RANK\n",
      "LABEL:  Rebels || NODE TYPE: FAC\n",
      "LABEL:    || NODE TYPE: ORG\n",
      "LABEL:  Kalemie || NODE TYPE: GPE\n",
      "LABEL:    || NODE TYPE: ORDINAL\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:  first || NODE TYPE: ORDINAL\n",
      "LABEL:  first || NODE TYPE: ORDINAL\n",
      "LABEL:    || NODE TYPE: NORP\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:  \n",
      " || NODE TYPE: GPE\n",
      "LABEL:  BAGOR || NODE TYPE: GPE\n",
      "LABEL:  Rebels || NODE TYPE: PERSON\n",
      "LABEL:  Rebels || NODE TYPE: PERSON\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:    || NODE TYPE: NORP\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:  Ule MATOBO GOBO || NODE TYPE: PERSON\n",
      "LABEL:    || NODE TYPE: ORG\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:  President || NODE TYPE: LOC\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:    || NODE TYPE: LOC\n",
      "LABEL:  Congo || NODE TYPE: GPE\n",
      "LABEL:  Congo || NODE TYPE: GPE\n",
      "RELATIONSHIP :fighting  \tLOC\tGoma\n",
      "RELATIONSHIP :a rally   \tLOC\tGoma\n",
      "RELATIONSHIP :a rally   \tLOC\tGoma\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "\n",
    "# new entity label\n",
    "LABEL = 'RANK'\n",
    "\n",
    "TRAIN_DATA = [\n",
    "    ('My name is Marcus BRODY. I am 15 years old', {\n",
    "        'entities': [(11, 24, 'PERSON')]\n",
    "    }),\n",
    "    ('I went to a rally in Goma', {\n",
    "        'entities': [(21, 25, 'LOC')]\n",
    "    }),\n",
    "    ('In late 2002', {\n",
    "        'entities': [(8, 12, 'DATE')]\n",
    "    }),\n",
    "    ('there was a lot of fighting in Goma', {\n",
    "        'entities': [(31, 35, 'LOC')]\n",
    "    }), \n",
    "    (\"I remember one of the commanders who spoke was Chief KOBONO\", {\n",
    "        'entities': [(47, 52, 'RANK')]\n",
    "    }),\n",
    "    (\"Chief\", {\n",
    "        'entities': [(0, 5, 'RANK')]\n",
    "    }),\n",
    "     ('there was a lot of fighting in Goma', {\n",
    "        'entities': [(19, 35, 'EVENT')]\n",
    "    })\n",
    "    \n",
    "]\n",
    "\n",
    "#add new entity\n",
    "nlp = spacy.load('en')\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')\n",
    "    ner.add_label(LABEL)   # add new entity label to entity recognizer\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "for i in range(20):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        nlp.update([text], [annotations], sgd=optimizer)\n",
    "nlp.to_disk('model')\n",
    "        \n",
    "# test the trained model\n",
    "for text, _ in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "        print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "        #print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "        \n",
    "#import text file\n",
    "witness_file = open('witness_text_clean.txt','r')\n",
    "text_witness = \"\"\n",
    "text_witness = witness_file.read() \n",
    "if text_witness != \"\":\n",
    "   text = text_witness\n",
    "\n",
    "#load spacy model\n",
    "nlp = spacy.load('model')\n",
    "#nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(text_witness)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print('LABEL: ',ent.text,'|| NODE TYPE:', ent.label_)\n",
    "    # Extract semi-structured statements\n",
    "    #print(\"Here are the things I know about Person:\")\n",
    "    #statements = textacy.extract.semistructured_statements(doc, \"I\")\n",
    "    #print('LABEL: ',ent.text,'|| NODE TYPE:', ent.label_)\n",
    "    #for statement in statements:\n",
    "    #    subject, verb, fact = statement\n",
    "    #    print({fact})\n",
    "\n",
    "#create relationships\n",
    "#for text in text_witness:\n",
    "doc = nlp(text_witness)\n",
    "relations = extract_lives_in_relations(doc)\n",
    "for r1, r2 in relations:\n",
    "    print('RELATIONSHIP :'+'{:<10}\\t{}\\t{}'.format(r1.text,r2.ent_type_,r2.text))   \n",
    "    \n",
    "    \n",
    "import csv    \n",
    "with open('WITNESS_OUTPUT_NODES.csv', 'w') as csvfile:\n",
    "    fieldnames = ['label', 'node_type']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for ent in doc.ents:\n",
    "        writer.writerow({'label': ent.text,'node_type': ent.label_})\n",
    "        \n",
    "#with open('WITNESS_OUTPUT_RELATIONS.csv', 'w') as csvfile:\n",
    "relations = extract_lives_in_relations(doc)\n",
    "#    for r1, r2 in relations:\n",
    "#        #print('RELATIONSHIP :'+'{:<10}\\t{}\\t{}'.format(r1.text,r2.ent_type_,r2.text))   \n",
    "#        fieldnames = ['event','LOC']\n",
    "#        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#        writer.writeheader()\n",
    "        #for ent in doc.ents:\n",
    "#        writer.writerow({'event': r1.text,'LOC': r2.text})\n",
    "        \n",
    "df = pd.DataFrame.from_dict(relations)\n",
    "df.drop_duplicates(keep=False, inplace=True)\n",
    "df.head()\n",
    "df.to_csv('WITNESS_OUTPUT_RELATIONS.csv',header=['label','node_type'],index_label='Id')\n",
    "#df.dropna(subset=['name', 'born'])\n",
    "        \n",
    "# Print the results\n",
    "\n",
    "#displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
